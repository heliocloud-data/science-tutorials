{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19769403-a150-4c71-aead-3ac6c971aa3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Guide to HelioCloud Tutorials\n",
    "S. Antunes (APL)\n",
    "April 2024\n",
    "\n",
    "There are many tutorials here in HelioClound, and we'll help walk you through them. At this point we'll assume you're already in your account and able to run a Notebook.  Our best introduction to 'why' is our [AGU_Demo-Populated.ipynb](AGU_Demo-Populated.ipynb) Notebook, which explains what HelioCloud can do and introduces a basic Python science example for looking at time-series data and at images.  We will walk you through an overview of HelioCloud, examples of data reads from AWS S3 storage, using Dask for compute power, and working in IDL.  We also include a link to a local copy of several core PyHC summer school package tutorials for AstroPy, HAPI, Kamodo, PlasmaPy, PySpedas, SolarMach, and SunPy.\n",
    "\n",
    "The core HelioCloud notebooks to date are:\n",
    "1) Overall intro in [AGU_Demo-Populated.ipynb](AGU_Demo-Populated.ipynb)\n",
    "2) basic file access of FITS, CDF and NetCDF data that is stored in AWS S3 cloud storage, in [S3-Explained.ipynb](S3-Explained.ipynb)\n",
    "3) 'bursting' a job onto multiple temporary CPUs in [Dask-Gateway-Example.ipynb](Dask-Gateway-Example.ipynb)\n",
    "4) combining accessing private or public S3 files with bursting via Dask in [S3-Dask-Demo.ipynb](S3-Dask-Demo.ipynb)\n",
    "5) finding datasets and lists of data files within one more more HelioClouds, in the [CloudCatalog-Demo.ipynb](CloudCatalog-Demo.ipynb)\n",
    "6) extended example MMS: searching for MMS data by instrument name and time range, then analyzing and plotting them, in [MMS-Catalog-Demo.ipynb](MMS-Catalog-Demo.ipynb)\n",
    "7) extended example SDO: searching for SDO data then processing a large set on multiple CPUs via Dask and gathering the results, in [SDO--Demo.ipynb](SDO--Demo.ipynb)\n",
    "\n",
    "We start off with the 'Science in the Browser' approach where the Juptyer Notebook suffices to find, analyze and plot data entirely within the cloud.  We also include additional material for power users who prefer to work in their own cloud VM or cloud console environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f7c4f-b563-499f-a435-7f005067d7b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Sample PyHC Tutorials\n",
    "\n",
    "To get a feel for using a Notebook (whether in cloud or on your laptop), we provide an excerpt of tutorials from the PyHC 2022 Summer School.  This highlights using the standard packages, fetching data, and plotting where the cloud usage and laptop usage are identical.\n",
    "\n",
    "1) [AstroPy_FITS-files-demo.ipynb](pyhc/AstroPy_FITS-files-demo.ipynb)\n",
    "2) [HAPI_01.ipynb](pyhc/HAPI_01.ipynb) basics and\n",
    "[HAPI_03.ipynb](pyhc/HAPI_03.ipynb) plotting\n",
    "3) [Kamodo_04-Visualization.ipynb](pyhc/Kamodo_04-Visualization.ipynb)\n",
    "4) [PlasmaPy-tutorial-instructor.ipynb](pyhc/PlasmaPy-tutorial-instructor.ipynb)\n",
    "5) [PySPEDAS_Summer_School_2022.ipynb](pyhc/PySPEDAS_Summer_School_2022.ipynb)\n",
    "6) [SolarMach_notebook.ipynb](pyhc/SolarMach_notebook.ipynb)\n",
    "7) [SunPy_part-1-search-and-download_Instructor.ipynb](pyhc/SunPy_part-1-search-and-download_Instructor.ipynb), \n",
    "[SunPy_part-2-data-structures_Instructor.ipynb](pyhc/SunPy_part-2-data-structures_Instructor.ipynb) and\n",
    "[SunPy_part-3-coordinates_Instructor.ipynb](pyhc/SunPy_part-3-coordinates_Instructor.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef9a2d4-5610-4ec0-bc17-336bf87f1a25",
   "metadata": {},
   "source": [
    "## About HelioCloud\n",
    "\n",
    "HelioCloud is cloud software for the Heliophysics research community.  HelioCloud is a time-saving tool for heliophysics researchers to rapidly access and analyze high-volume datasets from a web browser.  It includes easy-to-navigate cloud-based software with big data storage offers an innovative, streamlined approach for conducting research.  An Open Science framework breaks down barriers to collaboration by enabling multipoint access to shared data, code, and analysis tools in a secure environment.  You can download and install the software at your institution to connect with other HelioCloud communities and contribute to the project.  More at [https://heliocloud.org](https://heliocloud.org)\n",
    "\n",
    "If you are new to everything, look at our short [AGU_Demo-Populated.ipynb](AGU_Demo-Populated.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46834017-ac0c-4c9b-bd74-3fff4387ebfd",
   "metadata": {},
   "source": [
    "### First: What is S3?\n",
    "\n",
    "S3 stands for \"Simple Storage Service,\" which provides object storage for for AWS. https://aws.amazon.com/s3/\n",
    "\n",
    "It allows people to query and access data from a common location reference. The buckets can be made web accessible to users outside of daskhub if web access is enabled.\n",
    "\n",
    "S3 buckets are individual storage elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff4c464-0c37-4174-9946-c3c10813f7bf",
   "metadata": {},
   "source": [
    "## Science Part 1: Cloud storage and using multiple CPUs in Python\n",
    "\n",
    "Python practice examples for reading sample data in FITS, CDF or NetCDF that are stored in this cloud is in our [S3-Explained notebook](S3-Explained.ipynb). These make use of AstroPy for FITS files, cdflib for CDF files, and Xarray for NetCDF files.\n",
    "\n",
    "Dask is software that lets you 'burst' a job onto multiple temporary CPUs by defining then using a cluster of CPUs to lazily parallelize jobs. Using Dask in a notebook is in [Dask-Gateway-Example notebook](Dask-Gateway-Example.ipynb)\n",
    "\n",
    "We then combine reading from cloud S3 storage then using Dask to 'burst' the problem solving in [S3-Dask-Demo.ipynb](S3-Dask-Demo.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c6490-7e39-485e-83d0-1996fbda2cf2",
   "metadata": {},
   "source": [
    "## Science Part 2: Big Data Sets\n",
    "\n",
    "Cloud means never having to download datasets. Instead, you find data across multiple HelioClouds and directly access it without downloading it locally.  The [CloudCatalog API](https://pypi.org/project/cloudcatalog/) on top of the CloudCatalog sharing standard enables finding and listing cloud-stored scientific datasets such as CDAWeb, SDO, MMS and others.\n",
    "\n",
    "Our initial example for finding datasets and lists of data files within one more more HelioClouds is in the [CloudCatalog-Demo.ipynb](CloudCatalog-Demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524dd9cd-e3ba-4676-8212-f1ba84e66fa2",
   "metadata": {},
   "source": [
    "## Science Part 3: Using real MMS and SDO data\n",
    "\n",
    "We present two sample tasks wherein we first query the cloud for instrument data. We then pull a list of files for a given instrument and time range, then process it, all within the cloud (not using your local storage or laptop CPU).\n",
    "\n",
    "A serial example is searching for MMS data by instrument name and time range, then analyzing and plotting them, in the [MMS-Catalog-Demo notebook](MMS-Catalog-Demo.ipynb)\n",
    "\n",
    "We then add Dask 'burst' capabilities to tackle 2TB of data rapidly.  Here we search for SDO data then processing a large set on multiple CPUs via Dask and gathering the results, in the [SDO--Demo notebook](SDO--Demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c740698f-05b9-459a-99f7-2e4f430b9ea6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Working with IDL\n",
    "\n",
    "We provide an example for using IDL in the [IDL/IDL_examples notebook](IDL/IDL_examples.ipynb) and, additionally, accessing S3 in IDL in the [IDL/IDL-S3 notebook](IDL/IDL-S3.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8159f71d-db6d-495b-8c42-94d8d7945dc1",
   "metadata": {},
   "source": [
    "## Power users\n",
    "\n",
    "Pushing data on or off S3 using SFTP is in [Setup/SFTP service notebook](Setup/SFTP service.ipynb)\n",
    "\n",
    "A simple \"hello world\" in Fortran is in the [Additional/fortran_helloworld notebook](Additional/fortran_helloworld.ipynb)\n",
    "\n",
    "Updating your personal Conda environment is in the [Setup/Conda_instructions_for_cloud notebook](Setup/Conda_instructions_for_cloud.ipynb)\n",
    "\n",
    "Examples of writing your own S3 readers (for packages that do not yet support S3) are in [S3-Access-Demo](S3-Access-Demo.ipynb)\n",
    "\n",
    "Testing if GPUs are enabled, in the [Additional/GPU-Info notebook](Additonal/GPU-Info.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270f4de-b7fa-47f5-b8f4-c77273cd40a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
