{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edac1c14-2f71-4434-a3d3-ef4cfefddd6f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HelioCloud at AGU 2024\n",
    "## Big data, burst capability, collaboration, science-in-the-browser\n",
    "\n",
    "This notebook showcases HelioCloud, the NASA-created cloud platform for big data, high end computing, and data collaboration that any institution can set up.  It features:\n",
    "\n",
    "1) Science in your browser with a Python environment that 'just works'\n",
    "2) Ability to search and find data from many missions\n",
    "3) Computing on datasets without having to transfer them to your laptop\n",
    "4) Analysis and plotting interactively in Jupyter Notebooks\n",
    "5) Spinning up 100+ temporary CPUs for a big analysis task using Dask\n",
    "6) Examples from many of the PyHC core packages, such as HAPI, SunPy, Kamodo, PlasmaPy, pySat, PySpedas, and SpacePy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d42eff-17e3-4bfd-8116-c6f91c93b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure we have the proper versions, and plotting capability\n",
    "import os\n",
    "import pkg_resources\n",
    "try:\n",
    "    pkg_resources.require(\"cloudcatalog>0.5.0\")  # modified to use specific numpy\n",
    "except:\n",
    "    %pip install cloudcatalog --upgrade\n",
    "    os._exit(00)\n",
    "import matplotlib.pyplot as plt\n",
    "# optional, prettier inline Notebook plotting\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = ['svg'] \n",
    "import warnings\n",
    "warnings.filterwarnings( \"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afebbf7-65cc-4aa7-b0a4-be911f5e43c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HelioCloud shared cloud file registry (cloudcatalog)\n",
    "\n",
    "This is a simple standard for any dataset that enables users to access it via an API or directly.  The short definition is:\n",
    "\n",
    "    * Anyone can publish an S3 disk with a 'catalog.json' describing their datasets\n",
    "    * Each dataset has a flat-file <dataid>_YYYY.csv index of its contents\n",
    "    * These fetchable indexes have the form \"start, stop, file_location, filesize\" (plus optional metadata)\n",
    "    * A python client allows easy search and fetch using data IDs and time ranges\n",
    "    \n",
    "Here is an example querying for the filelists for MMS and for AIA for all of Aug 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abaf60-592b-44a1-88ad-49785c05492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudcatalog\n",
    "mms_ids = cloudcatalog.EntireCatalogSearch().search_by_id('srvy_ion')\n",
    "aia_ids = cloudcatalog.EntireCatalogSearch().search_by_keywords(['AIA 0193'])\n",
    "print(f\"ID search: found {len(mms_ids)} IDs matching 'srvy_ion' and {len(aia_ids)} IDs matching 'AIA 0193', picking first of each set.\")\n",
    "\n",
    "mmsID, aiaID = mms_ids[0]['id'], aia_ids[0]['id']\n",
    "start, stop = '2020-08-01T00:00:00Z', '2020-08-30T00:00:00Z'\n",
    "fr=cloudcatalog.CloudCatalog(\"s3://gov-nasa-hdrl-data1/\")\n",
    "mms_files = fr.request_cloud_catalog(mmsID, start_date=start, stop_date=stop)\n",
    "aia_files = fr.request_cloud_catalog(aiaID, start_date=start, stop_date=stop)\n",
    "print(f\"Filelists: found {len(mms_files)} {mmsID} files, {len(aia_files)} {aiaID} files for time range {start} to {stop}\")\n",
    "file1 = mms_files.iloc[0]['datakey']\n",
    "print(f\"\\nFor example, here is our {mmsID} files\")\n",
    "mms_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228e434-b251-483e-9ea3-a8a1bb0cb184",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's do something useful, like plot an MMS FEEPS electron survey files and a pair of AIA 0193Angstrom EUV images\n",
    "\n",
    "Here we go.  For MMS can use the 'cdflib' to remotely read the cloud-stored MMS datafile and plot it as usual.  This is identical to working with CDFs on your laptop, but with no network transfers. The data and the computation occur in the AWS cloud. We plot several FEEPS variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b127a5-0341-44ef-a646-e7879068b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdflib\n",
    "from matplotlib import pyplot as plt\n",
    "with cdflib.CDF(file1) as fin:\n",
    "    varnames = fin.cdf_info()['zVariables']\n",
    "    x = fin.varget(\"epoch\")\n",
    "    y = fin.varget(varnames[5])\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(varnames[5])\n",
    "    plt.title(f\"Plot of {varnames[5]}\")\n",
    "    plt.plot(x,y)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e27169-6075-4536-922e-4186cfe38656",
   "metadata": {},
   "source": [
    "Now images from AIA's EUVI.  Here we generate then plot AIA EUV images using AstroPy to read and PyPlot to plot.  Again, we are not copying the disk to our machine, but reading directly from the cloud to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30120d3-0d25-481b-832f-2815cefe5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.io.fits\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import sunpy.visualization.colormaps as cm\n",
    "import numpy as np\n",
    "\n",
    "cmap = matplotlib.colormaps['sdoaia193']\n",
    "for i in range(0,2200,700): #ele in aia_files.iloc[1:4]: #np.nditer(aia_files, REFS_OK=True):\n",
    "    fname = aia_files.iloc[i]['datakey']\n",
    "    try:\n",
    "        hdul = astropy.io.fits.open(fname)\n",
    "    except:\n",
    "        import s3fs\n",
    "        fs=s3fs.S3FileSystem(anon=True)\n",
    "        hdul = astropy.io.fits.open(fs.open(fname))\n",
    "    if i > 0:\n",
    "        plt.imshow(np.log(hdul[1].data), cmap=cmap)\n",
    "        plt.colorbar()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42612e7-9056-4cfe-b4d5-6651e3e5ad1f",
   "metadata": {},
   "source": [
    "## We can also use PyHC packages in this browser.\n",
    "\n",
    "We've already shown AstroPy, and now we give examples for HAPI time series data, SunPy image data, and Kamodo model generation.  These HAPI time series fetches or SunPy image calls or Kamodo model generations, executed within this Notebook, are the same as it would be on your laptop.  \n",
    "\n",
    "For HAPI, we look at DST1800 and Proton_QI1800 from OMNIWeb, from the 2022 PyHC Summer School tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10dce13-2246-4686-9d1c-9d8a04593f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hapiclient import hapi\n",
    "from hapiplot import hapiplot\n",
    "###    import math\n",
    "# HAPI test, OMNIWeb data\n",
    "# The data server\n",
    "server     = 'https://cdaweb.gsfc.nasa.gov/hapi'\n",
    "# The data set\n",
    "dataset    = 'OMNI2_H0_MRG1HR'\n",
    "# Start and stop times\n",
    "start      = '2021-10-25T00:00:00Z'\n",
    "stop       = '2021-12-01T00:00:00Z'\n",
    "# The HAPI convention is that parameters is a comma-separated list. Here we request two parameters.\n",
    "parameters = 'DST1800,Proton_QI1800'\n",
    "# Configuration options for the hapi function.\n",
    "opts = {'logging': False, 'usecache': True, 'cachedir': './hapicache' }\n",
    "# Get parameter data. See section 5 for for information on getting available datasets and parameters\n",
    "data, meta = hapi(server, dataset, parameters, start, stop, **opts)\n",
    "meta = hapiplot(data, meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a05032d-1c1f-4ba8-ad28-572da28f5c65",
   "metadata": {},
   "source": [
    "### SunPy\n",
    "This is the SunPy AIA Demo from https://docs.sunpy.org/en/stable/tutorial/maps.html, fetching a single demo AIA 171A EUV image and adding in WCS and prettier plotting.  Again the code to run this is identical to your laptop code, because HelioCloud is about science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101decc3-3680-49b2-abe8-cb63db2d08ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sunpy.map\n",
    "import sunpy.data.sample\n",
    "import astropy.units as u\n",
    "import matplotlib.pyplot as plt\n",
    "sunpy.data.sample.AIA_171_IMAGE\n",
    "my_map = sunpy.map.Map(sunpy.data.sample.AIA_171_IMAGE)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=my_map)\n",
    "my_map.plot(axes=ax, clip_interval=(1, 99.5)*u.percent)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b2127-5803-4f0b-a4ed-7ea883bbe33b",
   "metadata": {},
   "source": [
    "### Kamodo\n",
    "Here we run the Kamodo model generator example from the 2022 PyHC Summer School.  Note the use of interactive plots-- you can use the mouse to rotate or change the plot size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576d790-44f2-4324-87b3-51e2a8ae84c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kamodo import Kamodo\n",
    "import numpy as np\n",
    "x, y, z = np.meshgrid(np.linspace(-2,2,4),\n",
    "                      np.linspace(-3,3,6),\n",
    "                      np.linspace(-5,5,10))\n",
    "points = np.array(list(zip(x.ravel(), y.ravel(), z.ravel())))\n",
    "def fvec_Ncomma3(rvec_Ncomma3 = points):\n",
    "    return rvec_Ncomma3\n",
    "k = Kamodo(fvec_Ncomma3 = fvec_Ncomma3)\n",
    "k.plot('fvec_Ncomma3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606e026-3390-43d3-a2d0-8bcdcddf4159",
   "metadata": {},
   "source": [
    "## Ability to run a task with Lambdas (lambdas test) \n",
    "\n",
    "Python Lambdas are a quick way to run a function on a large set of data.  Here we do a very simple checksum on MMS files fetched from a CloudCatalog query.  You could just as easily add a function that does a more meaningful calculation, then run it on all the data with one line of invoking code.\n",
    "\n",
    "Again, with HelioCloud we are skipping the usual sluggish copying over of data before processing, and instead doing the computation on the data directly in the cloud.  This provides you with ready access to data, avoids filling disks, is faster, and lets you share code so others can collaborate (they'll already have access to the Petabytes of data in HelioCloud's public cloud archive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19079fc8-9c3e-4166-9c38-13d24bd46f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudcatalog\n",
    "fr=cloudcatalog.CloudCatalog(\"s3://gov-nasa-hdrl-data1/\")\n",
    "dataset_id1 = 'mms1_feeps_brst_electron'\n",
    "start = '2020-08-01T00:00:00Z'\n",
    "stop =   '2020-08-30T00:00:01Z'\n",
    "file_registry1 = fr.request_cloud_catalog(dataset_id1, start_date=start, stop_date=stop, overwrite=False)\n",
    "print(f\"{len(file_registry1)} files, operating lambda on first ten.\")\n",
    "print('Python Hash of File | Start Date | File Size')\n",
    "\n",
    "fr.stream(file_registry1[0:10], lambda bo, d, e, f: print(hash(bo.read()), d.replace(' ', 'T')+'Z', e, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7786b45-2954-4291-8fb0-d2d09e3acee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'imports_loaded_flag' not in locals():\n",
    "    import pysat\n",
    "# Testing out the xarray installation\n",
    "inst = pysat.Instrument('pysat', 'testmodel')\n",
    "inst.load(2009, 1)\n",
    "assert sum(sum(sum(inst.data['dummy1'].values))) >= 945378"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8d52f-9dae-48a0-8054-b6139db86285",
   "metadata": {},
   "source": [
    "### PySpedas\n",
    "Requires \"import pyspedas\" and \"from pytplot import tplot, get_data\", also \"import math\" for the assertion math.isclose() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00643e85-5dd6-4540-832c-42b63206e78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'imports_loaded_flag' not in locals():\n",
    "    import pyspedas\n",
    "    from pytplot import tplot, get_data\n",
    "    import math\n",
    "time_range = ['2020-04-20/06:00', '2020-04-20/08:00']\n",
    "pyspedas.solo.mag(trange=time_range, time_clip=True)\n",
    "pyspedas.mms.fgm(trange=time_range, time_clip=True, probe=2)\n",
    "tplot(['B_RTN','mms2_fgm_b_gsm_srvy_l2_bvec'])\n",
    "mag_data = get_data('mms2_fgm_b_gse_srvy_l2_bvec')\n",
    "assert math.isclose(sum(sum(mag_data.y)),152229.33203125)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9feddd-ff01-4b93-a8b8-3029f8cd1b64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cloud 'throw lots of CPUs at a problem' (Dask cluster) 'burst' test\n",
    "\n",
    "A big advantage of HelioCloud is the ability to send a computation to multiple CPUs, then gather the results.  This uses a library called Dask, which looks similar to a Python Lambda.  For example, given a function that does science 'process_fits_s3' and  a list of files 's3_files', the code is simply:\n",
    "```\n",
    "time_irrad = client.map(process_fits_s3, s3_files)\n",
    "all_data = client.gather(time_irrad)\n",
    "```\n",
    "There is an initial time hit to spin up the Cluster of extra CPUs, but then this and subsequent jobs are very rapid. Our code block 1 sets up the data environment and has our 'DO_SCIENCE' analysis routines. Block 2 starts the cluster.  Block 3 does the dask run (and can be re-run).  Once done, Block 4 shuts down the cluster for good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd2fa4-23ed-4d22-96ba-efcda3d959e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudcatalog\n",
    "import boto3\n",
    "import dask\n",
    "import io\n",
    "import time\n",
    "import re\n",
    "import astropy.io.fits\n",
    "from dask.distributed import Client\n",
    "from dask_gateway import Gateway, GatewayCluster\n",
    "    \n",
    "def DO_SCIENCE(mydata):\n",
    "    # Calculates total irradiance from an image.  You can put better science here\n",
    "    iirad = mydata.mean()\n",
    "    return iirad\n",
    "\n",
    "def process_fits_s3(s3key:str): # -> Tuple[str, float]:\n",
    "    \"\"\" grabs an S3 file then runs DO_SCIENCE() on it \"\"\"\n",
    "    sess = boto3.session.Session() # do this each open to avoid thread problem 'credential_provider'\n",
    "    s3c = sess.client(\"s3\")\n",
    "    [mybucket,mykey] = re.sub(r\"s3://\",\"\",s3key).split(\"/\",1)\n",
    "    try:\n",
    "        fobj = s3c.get_object(Bucket=mybucket,Key=mykey)\n",
    "        rawdata = fobj['Body'].read()\n",
    "        bdata = io.BytesIO(rawdata)\n",
    "        hdul = astropy.io.fits.open(bdata,memmap=False)        \n",
    "        date = hdul[1].header['T_OBS']\n",
    "        irrad = DO_SCIENCE(hdul[1].data)\n",
    "    except:\n",
    "        print(\"Error fetching \",s3key)\n",
    "        date, irrad = None, None       \n",
    "    return date, irrad\n",
    "\n",
    "frID = \"aia_0094\"\n",
    "fr=cloudcatalog.CloudCatalog(\"s3://gov-nasa-hdrl-data1/\")\n",
    "file_registry1 = fr.request_cloud_catalog(frID, start_date=start, stop_date=stop, overwrite=False)\n",
    "filelist = file_registry1['datakey'].to_list()\n",
    "s3_files = filelist[0:100] # small test set to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40d0955-f396-480c-b047-ec68c89dd907",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Now we initialize the Dask gateway and cluster, using your above parameters, to set up the virtual machines that will subsequently operate on the data. We use some non-optimized Dask parameters for setting up the run.\"\"\"\n",
    "gateway = Gateway()\n",
    "options = gateway.cluster_options()\n",
    "options.worker_cores, options.worker_memory = 2, 1\n",
    "cluster = gateway.new_cluster(options)\n",
    "client=Client(cluster)\n",
    "cluster.adapt(minimum=1, maximum=4)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2efc6-7a81-4866-8596-b69130b4cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "now=time.time()\n",
    "try:\n",
    "    time_irrad = client.map(process_fits_s3, s3_files) # do it\n",
    "    all_data = client.gather(time_irrad) # gather results\n",
    "    print(\"Done! Completed in time \",(time.time()-now)/60.0,\"minutes, on\",len(all_data),\"files\")\n",
    "except:\n",
    "    print(\"Cluster needs to be started (or re-started) before running code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937827c9-bb59-496d-8684-f1b1b31f9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "yn=input(\"Do you want to shut down the cluster, or re-use it? (y/r)?\")\n",
    "if yn == 'y':\n",
    "    cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03c65cc-b9db-4122-811a-e484b93f6236",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "To recap, HelioCloud lets you do the same science as on your laptop using the same Python packages you already use, but in the cloud. This means a stable pre-loaded Python environment, fast access to Terabyte- and Petabyte-sized datasets, and the ability to throw lots of CPUs at data- or computation-heavy problems. Because everyone using a HelioCloud has the same software environment and data access rights, you can collaborate more easily because you only need to share code, not envs and datasets.\n",
    "\n",
    "The HelioCloud 'stack' runs on AWS and is released as open source, so any institution can install it.  It is available via heliocloud.org.  HelioCloud is a NASA-funded software development effort and eagerly seeks community input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d33b37c-ce4a-4e01-bb8e-834feb62f9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
