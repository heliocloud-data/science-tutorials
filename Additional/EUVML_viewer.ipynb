{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fa8f0c-d860-4579-9250-e54b6e0106a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# EUVML dataset is STEREO EUVI + SOHO EIT\n",
    "Alex Antunes, June 2024\n",
    "\n",
    "This is an example of accessing a user-contributed S3 dataset, in this case just over 2 million 1MB 512x512 FITS files using STEREO header definitions for both STEREO EUVI and SOHO EIT.\n",
    "\n",
    "SOHO is 1996-2024, STEREOA is 2007-2024, STEREOB is 2007-2014.  Wavelengths are 171A, 195A, 284A, and 304A.\n",
    "\n",
    "Accessible via AWS 'S3' storage, which allows free access to HDRL data holdings.  Primary recommended interface is Python using the CloudCatalog protocol for querying file listings.  VSO intends to mirror traditionally as well.\n",
    "\n",
    "Datasets are: euvml, euvml_soho, euvml_stereoa, euvml_stereob, euvml_171, euvml_195, euvml_284, euvml_304, and euvml_\\<spacecraft>_\\<wavelength>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e1b676-ce38-49e5-b01e-3b7bdf2ebecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cloudcatalog\n",
    "except:\n",
    "    %pip install cloudcatalog --upgrade\n",
    "    \n",
    "import astropy.io.fits\n",
    "import sunpy.map\n",
    "\n",
    "cloud_endpoint=cloudcatalog.CloudCatalog(\"s3://gov-nasa-hdrl-data1/\")\n",
    "frID = \"euvml\"\n",
    "\n",
    "# Get metadata\n",
    "myjson = cloud_endpoint.get_entry(frID)\n",
    "print(f\"Metadata for {frID} is {myjson}\")\n",
    "start, stop = myjson['start'], myjson['stop']\n",
    "\n",
    "# Or hard-code times\n",
    "start, stop = '2011-01-01T00:00:00Z', '2011-01-02T23:59:59Z'\n",
    "\n",
    "# Get full file registry including metadata, also convert to just the file list.\n",
    "file_registry1 = cloud_endpoint.request_cloud_catalog(frID, start_date=start, stop_date=stop)\n",
    "filelist = file_registry1['datakey'].to_list()\n",
    "print(f\"\\nThere are {len(filelist)} files for ID {frID} in time range {start} to {stop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eac2830-d8ae-4300-8ac9-283db41b269e",
   "metadata": {},
   "source": [
    "# Sample AstroPy reader and SunPy Map reader\n",
    "\n",
    "AstroPy can be compiled to include the ability to read from cloud storage same as with filenames.  SunPy is developing that; at the time of this Notebook I find it easier to read in via AstroPy then convert to a SunPy Map object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe35c2-f930-4fdf-b5e7-a857cf06fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdul = astropy.io.fits.open(filelist[0])\n",
    "\n",
    "euvml_map = sunpy.map.Map(hdul[0].data,hdul[0].header)\n",
    "euvml_map.peek()\n",
    "\n",
    "print(f\"Spacecraft is {euvml_map.meta['TELESCOP']} for wavelength {euvml_map.meta['WAVELNTH']}\")\n",
    "\n",
    "file_registry1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d35507e-02eb-4cc1-bfa5-d60ca0b531f0",
   "metadata": {},
   "source": [
    "# Streaming through files\n",
    "\n",
    "Here are two streaming examples. The first runs a quick inline command using the API spec that guarantees the first four fields are s3key, start and stop times, and file size.  The second is a similar stream, in this case plotting the files.  Note in constructing the lambda that the 'stream' and 'stream_uri' commands mandate 4 variables be sent, but the catching functions can use or ignore any of them.   We send only the first ten files for this demo, but in a production setup you can send the entire filelist if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af50863d-9fca-4f8a-b4c8-6ec68f0354da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_endpoint.stream(file_registry1[:10], lambda s3key, start, stop, fsize: print(f\"{hash(s3key.read())}\\t{start}\\t{stop}\\t{fsize}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f87255-72aa-43bb-ba7a-922186823679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_euvml(fname):\n",
    "    hdul = astropy.io.fits.open(filelist[0])\n",
    "    euvml_map = sunpy.map.Map(hdul[0].data,hdul[0].header)\n",
    "    euvml_map.peek()\n",
    "\n",
    "cloud_endpoint.stream_uri(file_registry1[:3], lambda fname, start, stop, fsize: plot_euvml(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df7cb8a-1fb3-4aae-93d8-e1718996ef4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Finding catalogs\n",
    "\n",
    "You can do a search of the entire HelioCloud network to find what datasets exist.  Here we do searches on the ID, Title and keyword metadata within HelioCloud.  The last search, for example, will find all datasets tagged with '171' or '194' in their IDs, and finds AIA as well as our SOHO and STEREO datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccb634f-4870-4c11-9384-277462b2a2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysearch = cloudcatalog.EntireCatalogSearch()\n",
    "print(f\"Number of SOHO datasets, search by id: {len(mysearch.search_by_id('soho'))}\")\n",
    "print(f\"\\nIDs for all AIA datasets, search by title: {[s['id'] for s in mysearch.search_by_title('aia')]}\")\n",
    "print(f\"\\nIDs of all datasets whose id contain '193' or '194': {[s['id'] for s in mysearch.search_by_keywords(['193','194'])]}\")\n",
    "print(f\"\\nIDs of all 'euvml' datasets: {[s['id'] for s in mysearch.search_by_id('euvml')]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
