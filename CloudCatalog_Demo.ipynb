{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b61d5b43-f63f-46c8-bdd5-f7a4f5a8f1ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cloud Catalog Demo (feat. MMS)\n",
    "\n",
    "The CloudCatalog specification and accompanying Python client and demo notebook are a method for efficiently getting a list of data files stored in AWS S3 that are publicly accessible to scientists. Both data from the NASA public and TOPS (Transform to Open Science) AWS data stores and data that other HelioClouds have made public are equally accessible via this interface.  Currently cloudcatalog lets you access datasets you are aware of, or walk through the public listing of available datasets. \n",
    "\n",
    "In addition to querying which datasets are available, users can directly retrieve the list of files in the form of 'time, S3 file key, filesize' as a Pandas DataFrame.\n",
    "\n",
    "We jump into a quick demo of fetching a day's worth of MMS1 files.  We then step back to show how to query the 'catalog of catalogs' to explore and find datasets.  We close with a more extended MMS demo that fetches the list of files then plots them directly from cloud storage (no intermediate file transfers needed)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d066270-6a54-4101-8d99-24f5d2083feb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "The file catalog API is just \"import cloudcatalog\".  You also set a variable to point to where the global catalog of all known storage buckets (AWS S3 buckets) exist.  This is an index catalog that points to, basically, all known HelioClouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9422d5-00c2-4dce-9a4a-8b67fd503fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cloudcatalog\n",
    "import cdflib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9fe87d-e16c-4b08-8ae9-44ada8ab4fe5",
   "metadata": {},
   "source": [
    "# HAPI-like queries\n",
    "\n",
    "We will start with the main usage, 'give me a list of files to operate on', then backfill the way to search and explore catalogs after this example case.\n",
    "\n",
    "CloudCatalog uses a HAPI-like query to get a list of files for a given dataset id, over a given time range.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536970d4-034e-488e-a9f7-27685ff621fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one sample instruments and a time range\n",
    "dataset_id1 = 'MMS1_FEEPS_BRST_L2_ELECTRON'\n",
    "start = '2020-02-01T00:00:00Z'\n",
    "stop =   '2020-02-02T00:00:00Z'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a337b34-7a51-423c-ac51-62b906bdf2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open up the global Catalog\n",
    "cr = cloudcatalog.CatalogRegistry()\n",
    "fr = cloudcatalog.CloudCatalog(\"s3://gov-nasa-hdrl-data1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86fd3a4-9fe6-4ab3-95a2-3ef6b80f6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "filekeys_id1 = fr.request_cloud_catalog(dataset_id1,start_date=start,stop_date=stop)\n",
    "print(\"filekeys for \",dataset_id1,start,stop,\":\\n\",filekeys_id1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625dac1-03e0-4c6f-8ffe-2a08e81d0e01",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c993ce93-2cce-4e1c-abc3-568e7e53ac84",
   "metadata": {},
   "source": [
    "Now you can feed that list of file S3 locations to your program and work with your files.  Here's a simple example of looking at the metadata for the (arbitrarily chosen) 3rd file in that Pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5baf984-906a-4740-8729-85c75cda522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All info on item 3:\",filekeys_id1.iloc[2])\n",
    "print(\"Just the S3 key:\",filekeys_id1.iloc[2]['datakey'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b616b366-f0c1-4e30-9f65-d9b4b5c9c073",
   "metadata": {},
   "source": [
    "You can skip to the example at the end, where we actually access the files.  But first, what is CloudCatalog and how to use?\n",
    "\n",
    "# Catalog of Catalogs\n",
    "Now we step back to explore the catalogs that are available, to work up to that example.\n",
    "\n",
    "The 'CatalogRegistry()' call fetches a list of all S3 'buckets' (data repositories) that are known to the HelioCloud network.  This is the 'catalog of catalogs'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f763ffa-d59d-4370-a73e-4410002b1f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr=cloudcatalog.CatalogRegistry()\n",
    "cat = cr.get_catalog()\n",
    "print(\"get_catalog() provides JSON metadata for the Catalog of Catalogs, plus a list of known catalogs:\",cat)\n",
    "reg = cr.get_registry()\n",
    "print(\"get_registry() is a list of all known endpoints:\",reg)\n",
    "url = cr.get_endpoint(\"HelioCloud, including SDO\")\n",
    "print(\"get_endpoint:\",url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f758c3-38e4-44a5-bb7d-295f16eedabc",
   "metadata": {},
   "source": [
    "## Searching for data with EntireCatalogSearch\n",
    "\n",
    "This initial search accesses each HelioCloud's specific data holdings to create what you probably want, which is a list of all datasets available within the entire HelioCloud ecosystem.\n",
    "\n",
    "We include an example of a down or de-registered catalog to emphasize this index catalog points to HelioClouds, but doesn't manage them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8205ec-b3ad-4610-bec2-3f6bb57150cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysearch = cloudcatalog.EntireCatalogSearch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba84e09-a09f-472e-a3cd-b367f37d04e6",
   "metadata": {},
   "source": [
    "Now let us do something useful-- look for MMS1 FEEPS data, or ion data, or other items of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f5f133-9065-46a8-a695-43d2c0633bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysearch.search_by_id('mms1_feeps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b7f299-3258-4f32-97ce-c690e53656fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysearch.search_by_id('srvy_l2_ion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba464be3-7892-47e3-9a9f-c0943b8f254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysearch.search_by_keywords(['mms2', 'brst', 'apples'])[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8195cb-745f-4cfb-b398-9d4386ef86c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Working with the global catalog (..the name)\n",
    "This is primarily for admins and people looking for background information on other HelioClouds (rather than on other datasets).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605c229-f4fd-4dca-9311-c59dcdd2767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = cloudcatalog.CatalogRegistry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0359a0dd-239a-49e1-a6b5-a82f9f1cba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr.get_catalog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf3816-768c-4b00-81b7-2a624e8fa182",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr.get_registry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f018d2c-9aaf-4823-a7d5-29e6c87424ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = cr.get_endpoint('HelioCloud, including SDO')\n",
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4f0776-4164-4fa6-ba93-c82ec63b14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cr.catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc6f1a0-12ad-44b4-bb75-c75a1e6f7a18",
   "metadata": {},
   "source": [
    "## Working with a local catalog\n",
    "Here we browse all the data holdings within a specific disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95da03-c078-4617-a5ce-038c7fcc77c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fr=cloudcatalog.CloudCatalog(\"s3://gov-nasa-hdrl-data1/\")                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a09cef-56d7-43f4-a78d-e00ecf40ad8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "catalogs = fr.get_catalog()['catalog']\n",
    "print(f\"Here's the first four entries:\")\n",
    "for i in range(4): print(f\"{catalogs[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf973f8-6a05-430e-a966-ce6eff3478e7",
   "metadata": {},
   "source": [
    "# Useful search\n",
    "Given a dataset ID (from searching above or by knowing a dataset name from another catalog or search tool or even email), we can get a list of files for our desired dataset within our desired timespan.  Here's our example dataset from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a2bfc2-669b-4965-9549-03fdb9cf7506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one sample instruments and a time range\n",
    "dataset_id1 = 'MMS1_FEEPS_BRST_L2_ELECTRON'\n",
    "start = '2020-02-01T00:00:00Z'\n",
    "stop =   '2020-02-02T00:00:00Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530f97d4-5917-46f9-96de-4ca010abfdf6",
   "metadata": {},
   "source": [
    "Each dataset has metadata (in JSON format) providing additional information.  Here is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25157dd7-a4d3-447d-9863-e7f998810bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fr.get_entry(dataset_id1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c844b1e-6b97-436e-9c17-0c32693361a0",
   "metadata": {},
   "source": [
    "Now we get the actual file list of data items for our given instrument in our given time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead6f52-a491-471c-adcf-952d70099611",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_registry1 = fr.request_cloud_catalog(dataset_id1, start_date=start, stop_date=stop, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050c593-064d-4a99-a44e-10196cbb3f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_registry1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf9838-948f-4481-8eaf-afd4dddc7dc0",
   "metadata": {},
   "source": [
    "# Operating on files in bulk\n",
    "Here we can view metadata about the files, or plot them and otherwise extract data from them.\n",
    "\n",
    "First, some simple metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d2168-16d5-4268-9555-953fe5bd5ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Python Hash of File | Start Date | File Size')\n",
    "fr.stream(file_registry1[0:10], lambda bo, d, e, f: print(hash(bo.read()), d.replace(' ', 'T')+'Z', e.replace(' ','T')+'Z',f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d29768-5e96-434e-a52d-b4a27d754589",
   "metadata": {},
   "source": [
    "We define a plotting routine for CDF files here. You can (as with any code) define whatever functions you want to rip through each datafile.  We chose to plot it for this demo to show the data is accessed via S3 and loaded into this program without having to copy any files around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13920449-feaa-4362-a302-97bd07c2b10c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_cdf(s3_uri, d, e, f):\n",
    "    print(\"fetching \",s3_uri)\n",
    "\n",
    "    cdf = cdflib.CDF(s3_uri)\n",
    "\n",
    "    # Get the variable name and its data\n",
    "    #var_name = cdf.cdf_info()[\"zVariables\"][2]\n",
    "    #var_data = cdf.varget(var_name)\n",
    "    var_data = cdf.varget(1)\n",
    "    var_name=\"data\"\n",
    "    # Plot the variable\n",
    "    plt.figure()\n",
    "    plt.plot(var_data)\n",
    "    plt.xlabel(\"Index\")\n",
    "    plt.ylabel(var_name)\n",
    "    plt.title(f\"Plot of {var_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0832d7-7a96-477d-86f7-cf9a866f8e44",
   "metadata": {},
   "source": [
    "# The real stuff\n",
    "\n",
    "This is our simple runner that takes the file list and runs the plot command. In this case, we pull a subset of the list e.g.  file_registry1[:3] will pull only the first three files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4248c-e669-4405-bbfc-5c0abc195a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of zVariables | Start Date | File Size')\n",
    "fr.stream_uri(file_registry1[:3], lambda s3_uri, d, e, f: plot_cdf(s3_uri, d, e, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40007b2d-52a7-4d0e-b271-611575156d59",
   "metadata": {},
   "source": [
    "That's it: find a dataset, get a list of files for a given time range, and operate on all the files in bulk."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
