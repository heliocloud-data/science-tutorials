{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fee75c-58c5-45fa-9a62-8e96aa69e255",
   "metadata": {},
   "source": [
    "# GPU vs. CPU Time Testing\n",
    "\n",
    "In this notebook, we compare the speed at which the CPU and the GPU complete a matrix multiplication of the same random arrays.\n",
    "\n",
    "First, do the imports. We're setting the TensorFlow \"log level\" to 2 so that it supresses warnings, but still outputs whether the TensorFlow operations are taking place on the CPU, or the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce3e81b-dc8b-47b6-b093-45bca457eb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set log level to 3 to supress INFO and WARNING messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2b0c0-5ce3-4f18-baaa-49bbeb9c8aa1",
   "metadata": {},
   "source": [
    "### Create some tensors\n",
    "\n",
    "Create the matrices that we'll be working with. TensorFlow requires that the values be in float32 format for doing matrix multiplication on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2d3cd30-0269-4b79-b53e-bdf0d2d31b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_a = np.random.rand(4000,6000).astype(np.float32)\n",
    "array_b = np.random.rand(6000,4000).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7d179f-9c86-474d-a4dd-e9ebb4734a57",
   "metadata": {},
   "source": [
    "### Matrix multiplication on the CPU\n",
    "\n",
    "We run the \"%%time\" magic command and get the total runtime of the cell as the \"Wall time\" at the bottom of the cell output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403db0de-42c4-4d7d-85a2-a1cd1a80b0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _MklMatMul in device /job:localhost/replica:0/task:0/device:CPU:0\n",
      "tf.Tensor(\n",
      "[[1514.3379 1538.084  1503.3572 ... 1517.2496 1528.9951 1515.0752]\n",
      " [1509.2175 1526.9805 1500.2554 ... 1531.8606 1521.5109 1519.6726]\n",
      " [1516.6642 1526.9082 1497.382  ... 1504.0918 1509.9412 1505.5955]\n",
      " ...\n",
      " [1495.1278 1502.5363 1467.5347 ... 1489.9993 1489.1797 1473.3014]\n",
      " [1496.9824 1518.2943 1494.0378 ... 1504.7379 1516.57   1499.1046]\n",
      " [1496.7546 1499.8086 1470.2448 ... 1482.6279 1487.8771 1477.4657]], shape=(4000, 4000), dtype=float32)\n",
      "CPU times: user 3.12 s, sys: 261 ms, total: 3.39 s\n",
      "Wall time: 701 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "  # Place tensors on the CPU\n",
    "  a = tf.constant(array_a)\n",
    "  b = tf.constant(array_b)\n",
    "  # Run the matrix multiplication on the CPU\n",
    "  c = tf.matmul(a, b)   \n",
    "    \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5699b0a7-9917-42d7-baf6-c2b9b62d039f",
   "metadata": {},
   "source": [
    "### Matrix multiplication on the GPU\n",
    "\n",
    "Now we do the same calculation on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91fe1b22-78b2-46c4-8468-3830ef6ff07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op _EagerConst in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "Executing op MatMul in device /job:localhost/replica:0/task:0/device:GPU:0\n",
      "tf.Tensor(\n",
      "[[1514.3392 1538.0817 1503.3596 ... 1517.2487 1528.9945 1515.0747]\n",
      " [1509.2147 1526.9796 1500.2537 ... 1531.8633 1521.5155 1519.6733]\n",
      " [1516.6649 1526.9099 1497.3842 ... 1504.0929 1509.9387 1505.5957]\n",
      " ...\n",
      " [1495.1288 1502.5367 1467.5345 ... 1490.0023 1489.1785 1473.3015]\n",
      " [1496.9811 1518.2958 1494.0375 ... 1504.7385 1516.5706 1499.1068]\n",
      " [1496.7513 1499.8108 1470.2441 ... 1482.6249 1487.8734 1477.4644]], shape=(4000, 4000), dtype=float32)\n",
      "CPU times: user 228 ms, sys: 270 ms, total: 497 ms\n",
      "Wall time: 495 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "  # Place tensors on the GPU\n",
    "  a = tf.constant(array_a)\n",
    "  b = tf.constant(array_b)\n",
    "  # Run the matrix multiplication on the GPU\n",
    "  c = tf.matmul(a, b)   \n",
    "    \n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e38ff-efc5-4e68-887f-299f2fa5fafb",
   "metadata": {},
   "source": [
    "### Final time comparison\n",
    "\n",
    "When you ran the two above cells, you should have found that the calculation is almost twice as fast on the GPU in comparison to the CPU. Continue working your way through the other tutorial Notebooks in this directory to continue to learn the ins and outs of doing data analysis with GPU accelerated computing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
