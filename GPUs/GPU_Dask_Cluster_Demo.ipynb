{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d91dd39b-e386-4d82-9e0d-69458292cc55",
   "metadata": {},
   "source": [
    "# Dask Bursting GPU vs. CPU Speed Testing\n",
    "\n",
    "In this notebook, we compare the speed at which the CPU and the GPU complete a matrix multiplication of the same random arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca26bfa-f288-4127-b2f5-02a4d5d50f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "import dask\n",
    "import io\n",
    "import re\n",
    "import logging\n",
    "import s3fs\n",
    "\n",
    "from astropy.io import fits\n",
    "from dask.distributed import Client\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4815bc6d-67ea-467a-85f3-264234df63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway, GatewayCluster\n",
    "gateway = Gateway()\n",
    "options = gateway.cluster_options()\n",
    "\n",
    "# We're setting some defaults here just for grins... \n",
    "# I like the pangeo/base-notebook image for the workers since it has almost every library you'd need on a worker\n",
    "# In our environment, without setting these, the widget will default to the same image that the notebook itself is running, \n",
    "# as well as 2 cores and 4GB memory per worker\n",
    "\n",
    "options.image = 'public.ecr.aws/q3h7b4o8/heliocloud/helio-daskhub-mltf:2025.01.29'\n",
    "options.worker_cores = 4\n",
    "options.worker_memory = 7\n",
    "options.profile='gpu-xlarge'\n",
    "\n",
    "# This calls the widget\n",
    "options  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f85f27-d1f3-4fd3-82a9-c04aa962db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = gateway.new_cluster(options)\n",
    "client = cluster.get_client()\n",
    "n_workers = 3\n",
    "cluster.scale(n_workers)\n",
    "#cluster.adapt(minimum=1, maximum=n_workers)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efcdb01-946e-46f3-bee1-075fb388b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nvidia_driver_version():\n",
    "    import pynvml\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    return pynvml.nvmlSystemGetDriverVersion(), len(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f1f9f-b17d-45a6-b025-a619fc253fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.run(get_nvidia_driver_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b2b94c-45fb-4b1d-9789-d8cd264f7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "array_a = np.random.rand(4000,6000).astype(np.float32)\n",
    "array_b = np.random.rand(6000,4000).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d80d9-7261-4ecd-b8c7-3beee6663f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_tensor_math(array_a, array_b):\n",
    "    import os\n",
    "    # Set log level to 3 to supress INFO and WARNING messages\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "    import tensorflow as tf\n",
    "    \n",
    "    num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "    tf.debugging.set_log_device_placement(True)\n",
    "    \n",
    "    a = tf.constant(array_a)\n",
    "    b = tf.constant(array_b)\n",
    "    #c = tf.matmul(a, b)\n",
    "\n",
    "    # Run the matrix multiplication 100 times on the CPU\n",
    "    for i in range(1000):\n",
    "        c = tf.matmul(a, b)\n",
    "    \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fae735-5769-4c5b-aa56-d95b07168269",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a_scatter = client.scatter(array_a)\n",
    "b_scatter = client.scatter(array_b)\n",
    "c = client.submit(do_tensor_math, a_scatter, b_scatter)\n",
    "#print(c.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f10928-94cc-4aea-85ed-4eefb133c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b222581-ea53-4f9d-873b-3418bc41fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a2de19-6c27-44a6-b23e-b877b7d41ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d4a162-2dbf-4060-95eb-a14785072ee0",
   "metadata": {},
   "source": [
    "### Cell #1\n",
    "\n",
    "First, do the imports. We're setting the TensorFlow \"log level\" to 3 so that it supresses warnings, but still outputs whether the TensorFlow operations are taking place on the CPU, or the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce3e81b-dc8b-47b6-b093-45bca457eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set log level to 3 to supress INFO and WARNING messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2b0c0-5ce3-4f18-baaa-49bbeb9c8aa1",
   "metadata": {},
   "source": [
    "### Cell #2: Create some tensors\n",
    "\n",
    "Create the matrices that we'll be working with. TensorFlow requires that the values be in float32 format for doing matrix multiplication on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3cd30-0269-4b79-b53e-bdf0d2d31b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_a = np.random.rand(4000,6000).astype(np.float32)\n",
    "array_b = np.random.rand(6000,4000).astype(np.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d1d82485-cf10-472b-afe4-ef1f28b20934",
   "metadata": {},
   "source": [
    "### Cell #3: Matrix multiplication on the CPU\n",
    "\n",
    "We multiply the matrices on the CPU once. In Cell #1, we enabled TensorFlow to log device placement. As a result, we this cell should output the line \"Executing op _MklMatMul in device /job:localhost/replica:0/task:0/device:CPU:0\" to show that the operation is taking place on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403db0de-42c4-4d7d-85a2-a1cd1a80b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/CPU:0'):\n",
    "  # Place tensors on the CPU\n",
    "  a = tf.constant(array_a)\n",
    "  b = tf.constant(array_b)\n",
    "  c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e308cb-7b4b-4a58-b299-df185b366ffc",
   "metadata": {},
   "source": [
    "### Cell #4: Increase the Processing Demand on the CPU\n",
    "\n",
    "Now let's do the same matrix multiplication 100 times. We expect that this cell should take around 30 seconds to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773e957-b7e6-449b-ad39-d788079721c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "%%time\n",
    "start_time = time.time()\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "  # Place tensors on the CPU\n",
    "  a = tf.constant(array_a)\n",
    "  b = tf.constant(array_b)\n",
    "    \n",
    "  # Run the matrix multiplication 100 times on the CPU\n",
    "  for i in range(100):\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "end_time = time.time()\n",
    "cpu_execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce51b82-90b5-4545-8711-782b513e4e07",
   "metadata": {},
   "source": [
    "### Cell #5: Display CPU Processing Time\n",
    "\n",
    "Run the cell below to display how many seconds it look for Cell #4 to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9423867-7e6f-4243-9ae7-3fb5d3cda836",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Execution time on the CPU: {cpu_execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5699b0a7-9917-42d7-baf6-c2b9b62d039f",
   "metadata": {},
   "source": [
    "### Cell #6: Matrix multiplication on the GPU\n",
    "\n",
    "Now we do the same calculation on the GPU. The device placement log should show that we are now operating on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e525ec45-3fa0-4614-9704-b1b5f9ea5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/GPU:0'):\n",
    "  # Place tensors on the GPU\n",
    "  a = tf.constant(array_a)\n",
    "  b = tf.constant(array_b)\n",
    "  c = tf.matmul(a, b)\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b976d6b6-c77b-4c24-a9f6-29fbe8a81e14",
   "metadata": {},
   "source": [
    "### Cell #7: Increase the Processing Demand on the GPU\n",
    "\n",
    "Run the next cell to repeat the same matrix multiplication 100 times. This should take far less time than when we ran it on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad6b736-8c7d-492a-b4f0-66053e0db167",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#start_time = time.time()\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "  # Place tensors on the GPU\n",
    "  a = tf.constant(array_a)\n",
    "  b = tf.constant(array_b)\n",
    "    \n",
    "  # Run the matrix multiplication 100 times on the GPU\n",
    "  for i in range(1000):\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "#print(c)\n",
    "\n",
    "#end_time = time.time()\n",
    "#gpu_execution_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d7d9e-2da1-463e-b145-7d9f59b5a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1860bb11-a81f-4572-a155-3e559bb28ad6",
   "metadata": {},
   "source": [
    "### Cell #8: Display GPU Processing Time\n",
    "\n",
    "Run the cell below to display how many seconds it look for Cell #7 to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc30a6-f78c-496b-9324-713a5f71c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Execution time on the GPU: {gpu_execution_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8e38ff-efc5-4e68-887f-299f2fa5fafb",
   "metadata": {},
   "source": [
    "### Final time comparison\n",
    "\n",
    "Following this tutorial, you should have found that the processing speed of the GPU is *significantly* faster than the CPU. Perhaps you can see yourself speeding up your own data analysis by moving from CPU to GPU computing. Continue working your way through the other tutorial Notebooks in this directory to to learn the ins and outs of doing data analysis with GPU accelerated computing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
