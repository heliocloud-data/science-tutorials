{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<CENTER>\n",
    "<H1 style=\"color:red\">\n",
    "SMCE Heliophysics S3 Bucket Tutorial\n",
    "</H1>\n",
    "</CENTER>\n",
    "<img src=\"banner.jpg\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to Upload data SMCE helio-public S3 bucket\n",
    "\n",
    "### You will need to create the conda environment for this notebook, use 'environment-s3-demo.yml' with the command (in the terminal)\n",
    "### > conda env create -f environment-s3-demo.yml\n",
    "\n",
    "### then make sure to select the 'conda env:s3-demo' environment for this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First:  What is S3? \n",
    "\n",
    "S3 stands for \"Simple Storage Service,\" which provides object storage for for AWS.  https://aws.amazon.com/s3/ \n",
    "\n",
    "It allows people to query and access data from a common location reference.  The buckets can be made <a href=\"https://stackoverflow.com/q/16784052\">web accessible to users outside of daskhub</a> if web access is enabled.    \n",
    "\n",
    "S3 buckets are individual storage elements. \n",
    "\n",
    "## Accessing S3 buckets\n",
    "\n",
    "To <a href= \"https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/ls.html\">get a list of the S3 buckets</a> on the SMCE Daskhub, enter this at a terminal prompt : <br>\n",
    "`aws s3 ls`\n",
    "\n",
    "To view the contents of a specific bucket, reference it with s3:// <br>\n",
    "`aws s3 ls s3://helio-public/`\n",
    ">            PRE SDO/\n",
    ">            PRE SOHO/\n",
    "\n",
    "(Note: \"PRE\" stands for prefix, so SDO/ is an AWS prefix with name SDO.) \n",
    "<hr>\n",
    "\n",
    "The external reference for this bucket is https://helio-public.s3.us-east-1.amazonaws.com/\n",
    "\n",
    "## Basic commands using S3 buckets\n",
    "\n",
    "To create a new directory, just reference it:<br>\n",
    "`aws s3 ls s3://helio-public/yourname/yourdir`\n",
    "\n",
    "then you can copy to the bucket as if it was a unix folder:<br>\n",
    "`aws s3 cp yourfile s3://helio-public/yourname/yourdir`\n",
    "\n",
    "if you need access to a bucket that has restricted access, you have to run aws-mfa first:<br>\n",
    "`~/aws-mfa default`\n",
    "\n",
    "you may need to change it to have execute permission first:<br>\n",
    "`chmod 755 ~/aws-mfa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import logging\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from re import search\n",
    "\n",
    "from astropy.io import fits\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the bucket to upload to\n",
    "bucket_name = 'helio-public'\n",
    "\n",
    "# location in the bucket to use\n",
    "bucket_path = '/SDO/AIA/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull data from bucket into memory and work with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDO/AIA/AIA_L4_20141018_000001_94.fits\n",
      "[<astropy.io.fits.hdu.image.PrimaryHDU object at 0x7fb88a2fdbb0>]\n"
     ]
    }
   ],
   "source": [
    "# open up a Boto session and create an S3 client, then \n",
    "# iterate thru files \n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "\n",
    "# Iterates through all the objects, doing the pagination for you. Each obj\n",
    "# is an ObjectSummary, so it doesn't contain the body. You'll need to call\n",
    "# get to get the whole body.\n",
    "for obj in bucket.objects.all():\n",
    "    key = obj.key\n",
    "    \n",
    "    if search ('fits', key):\n",
    "        print (key)\n",
    "        body = obj.get()['Body'].read()\n",
    "    \n",
    "        # load fits file\n",
    "        hdulist = fits.open(io.BytesIO(body))\n",
    "        print (hdulist)\n",
    "        \n",
    "        # <WORK WITH FILE HERE>\n",
    "\n",
    "        # only doing ONE object in the demo\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
