{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<CENTER>\n",
    "<H1 style=\"color:red\">\n",
    "SMCE Heliophysics DaskHub S3 Bucket Tutorial\n",
    "</H1>\n",
    "</CENTER>\n",
    "<!--<img src=\"./banner.jpg\">-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to process data in SMCE helio-public S3 bucket using Dask\n",
    "\n",
    "<i>Note:  This document is maintained through the SMCE HSD Cloud gitlab.</i>\n",
    "\n",
    "This is a simple example showing how to get a list of FITS files, run them through Dask workers to pull them from disk and examine the header keyword(s). \n",
    "\n",
    "You can use this notebook to test out various parameters you might feed to Dask; Consider the 'batch size', number of workers, number of cores per worker and memory per worker. Use the dashboard link to inspect how Dask is performing. Try both manual and automatic scaling strategies. See if you can get it to process 100 files in 20 sec or less!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First:  What is S3? \n",
    "\n",
    "S3 stands for \"Simple Storage Service,\" which provides object storage for for AWS.  https://aws.amazon.com/s3/ \n",
    "\n",
    "It allows people to query and access data from a common location reference.  The buckets can be made <a href=\"https://stackoverflow.com/q/16784052\">web accessible to users outside of daskhub</a> if web access is enabled.    \n",
    "\n",
    "S3 buckets are individual storage elements. \n",
    "\n",
    "## Accessing S3 buckets\n",
    "\n",
    "To <a href= \"https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/ls.html\">get a list of the S3 buckets</a> on the SMCE Daskhub, enter this at a terminal prompt : <br>\n",
    "`aws s3 ls`\n",
    "\n",
    "To view the contents of a specific bucket, reference it with s3:// <br>\n",
    "`aws s3 ls s3://helio-public/`\n",
    ">            PRE SDO/\n",
    ">            PRE SOHO/\n",
    "\n",
    "(Note: \"PRE\" stands for prefix, so SDO/ is an AWS prefix with name SDO.) \n",
    "<hr>\n",
    "\n",
    "The external reference for this bucket is https://helio-public.s3.us-east-1.amazonaws.com/\n",
    "\n",
    "## Basic commands using S3 buckets\n",
    "\n",
    "To create a new directory, just reference it:<br>\n",
    "`aws s3 ls s3://helio-public/yourname/yourdir`\n",
    "\n",
    "then you can copy to the bucket as if it was a unix folder:<br>\n",
    "`aws s3 cp yourfile s3://helio-public/yourname/yourdir`\n",
    "\n",
    "copying multiple files is a bit more intricate, you need to put the multiple files in a directory first:<br>\n",
    "`aws s3 cp sourcedir/ s3://helio-public/yourname/yourdir --recursive`\n",
    "\n",
    "if you need access to a bucket that has restricted access, you have to run aws-mfa first:<br>\n",
    "`~/aws-mfa default`\n",
    "\n",
    "where default is a profile. To see available profiles:<br>\n",
    "`cat ~/.aws/credentials`\n",
    "\n",
    "you may need to change it to have execute permission first:<br>\n",
    "`chmod 755 ~/aws-mfa`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (The code below needs to be commented for instructional purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "import dask\n",
    "import io\n",
    "import logging\n",
    "import s3fs\n",
    "\n",
    "from astropy.io import fits\n",
    "from dask.distributed import Client\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the bucket to upload to\n",
    "bucket_name = 'gov-nasa-hdrl-data1'\n",
    "\n",
    "# location in the bucket to use (a days worth of 211 A data from AIA on SDO for the date 2022-11-27)\n",
    "bucket_path = 'sdo/aia/20221127/0211/'\n",
    "\n",
    "# number of workers to use, for automatic scaling, our max number\n",
    "n_workers = 10\n",
    "\n",
    "# memory per worker (in Gb)\n",
    "w_memory = 2\n",
    "\n",
    "# cores per worker\n",
    "w_cores = 2\n",
    "\n",
    "# number of files to test against (360 max)\n",
    "n_files = 100\n",
    "\n",
    "# Number of files we release to be worked on by all workers at a time\n",
    "# the higher the number the more files being processed concurrently, but also\n",
    "# the greater the memory consumed. \n",
    "batch_size = 50\n",
    "\n",
    "# use Manual (if False, then uses Automatic scaling)\n",
    "use_manual_scaling = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize the cluster and assign the client to the cluster, display the cluster widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway, GatewayCluster\n",
    "gateway = Gateway()\n",
    "options = gateway.cluster_options()\n",
    "\n",
    "# We're setting some defaults here just for grins... \n",
    "# I like the pangeo/base-notebook image for the workers since it has almost every library you'd need on a worker\n",
    "# In our environment, without setting these, the widget will default to the same image that the notebook itself is running, \n",
    "# as well as 2 cores and 4GB memory per worker\n",
    "\n",
    "options.worker_cores=w_cores\n",
    "options.worker_memory=w_memory\n",
    "# options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = gateway.new_cluster(options)\n",
    "client = cluster.get_client()\n",
    "\n",
    "if use_manual_scaling:\n",
    "    \n",
    "    # manual scaling (n_workers defined above)\n",
    "    cluster.scale(n_workers)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Adaptively scale between 1 and n_workers (the max)\n",
    "    cluster.adapt(minimum=1, maximum=n_workers)\n",
    "\n",
    "# uncomment this if you want to use the GUI\n",
    "#cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-a05f0064-04bf-11ee-8d58-dad710c6e21b</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_gateway.GatewayCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/services/dask-gateway/clusters/daskhub.0f89be2f89864308a352fbda0ca887d3/status\" target=\"_blank\">/services/dask-gateway/clusters/daskhub.0f89be2f89864308a352fbda0ca887d3/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <button style=\"margin-bottom: 12px;\" data-commandlinker-command=\"dask:populate-and-launch-layout\" data-commandlinker-args='{\"url\": \"/services/dask-gateway/clusters/daskhub.0f89be2f89864308a352fbda0ca887d3/status\" }'>\n",
       "                Launch dashboard in JupyterLab\n",
       "            </button>\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div style='background-color: #f2f2f2; display: inline-block; padding: 10px; border: 1px solid #999999;'>\n",
       "  <h3>GatewayCluster</h3>\n",
       "  <ul>\n",
       "    <li><b>Name: </b>daskhub.0f89be2f89864308a352fbda0ca887d3\n",
       "    <li><b>Dashboard: </b><a href='/services/dask-gateway/clusters/daskhub.0f89be2f89864308a352fbda0ca887d3/status' target='_blank'>/services/dask-gateway/clusters/daskhub.0f89be2f89864308a352fbda0ca887d3/status</a>\n",
       "  </ul>\n",
       "</div>\n",
       "\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tls://192.168.27.39:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create client, show url we can go to to monitor progress\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scan data from bucket and make a simple list of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sdo/aia/20221127/0211/sdo_aia_h2_20221127T000000_0211_v1.fits'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get our list of files/s3 objects\n",
    "cached = True\n",
    "import json\n",
    "if (cached):\n",
    "    with open ('s3_data.json') as f:\n",
    "        s3_files = json.load(f)['files']\n",
    "\n",
    "else:\n",
    "\n",
    "    # initialize connection to S3 bucket\n",
    "    #s3_client = boto3.resource('s3')\n",
    "    s3_client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "    objs = s3_client.list_objects(Bucket=bucket_name, Prefix=bucket_path)\n",
    "\n",
    "    #print (objs)\n",
    "    # Iterates through all the objects, doing the pagination for you. Each obj\n",
    "    # is an ObjectSummary, so it doesn't contain the body. You'll need to call\n",
    "    # get to get the whole body.\n",
    "    s3_files = []\n",
    "    for obj in objs['Contents']: #bucket.objects.all():\n",
    "        #print (obj)\n",
    "        key = obj['Key']\n",
    "\n",
    "        if search ('fits', key):\n",
    "            s3_files.append(key)\n",
    "    \n",
    "    # write / cache files to local listing (speed purposes)\n",
    "\n",
    "    with open('s3_data.json', 'w') as outfile:\n",
    "        json.dump({'files' : s3_files}, outfile)\n",
    "    \n",
    "\n",
    "s3_files[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define some routines we will use for doing work with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_fits_s3 (s3_file_name:str, bucket_name:str)->object:\n",
    "    \n",
    "    \"\"\" Open a FITS file on an S3 bucket, pass back a binary blob of file info.\n",
    "    \"\"\"\n",
    " \n",
    "    fs = s3fs.S3FileSystem()\n",
    "    \n",
    "    with fs.open(bucket_name+'/'+s3_file_name, 'rb') as f:\n",
    "        #fits_hdul = fits.open(io.BytesIO(f.read()))\n",
    "        #fits_hdul.info()\n",
    "    \n",
    "        # return bytes\n",
    "        return f.read()\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_header(f_bytes:object)->str:\n",
    "    \n",
    "    \"\"\" Marshal the bytes into a astropy FITS object, and pass back \n",
    "    \"\"\"\n",
    "    return fits.open(io.BytesIO(f_bytes))   \n",
    "    \n",
    "def work_on_data (client:dask.distributed.client.Client, bucket_name:str, files:list=[])->int:\n",
    "    \n",
    "    \"\"\" \n",
    "    Main routine which Dask will use to 'do work'. Each worker will run this.\n",
    "    \"\"\"\n",
    "    \n",
    "    # pull files from S3 as bytes\n",
    "    f_bytes_list = client.map(open_fits_s3, files, bucket_name=bucket_name)\n",
    "    \n",
    "    # read bytes as FITS file, grab header\n",
    "    hduls = client.map(get_header, f_bytes_list)\n",
    "    \n",
    "    # trigger distributed task, marshall result back to local memory\n",
    "    headers=[]\n",
    "    try:\n",
    "        headers = client.gather(hduls)\n",
    "    except Exception as er:\n",
    "        print (f\"Caught exception {er}\")\n",
    "    \n",
    "    # return the primary header back for analysis\n",
    "    return [hdr[1].header for hdr in headers]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Do the cloud processing, using Dask to 'burst' into other VMs\n",
    "Using our gathered list of FITS files, chunk it out in batches and provide file list chunks to the workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workers: 10, cores/worker:2, mem/worker: 2\n",
      "client:<Client: 'tls://192.168.27.39:8786' processes=5 threads=10, memory=10.00 GiB> Finished 50 files\n",
      "client:<Client: 'tls://192.168.27.39:8786' processes=5 threads=10, memory=10.00 GiB> Finished 50 files\n",
      "CPU times: user 2.78 s, sys: 1.56 s, total: 4.34 s\n",
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if n_files > len(s3_files):\n",
    "    n_files = len(s3_files)\n",
    "    \n",
    "def chunks(lst, n):\n",
    "    \"\"\" program to divide our file list into chunks for each worker \"\"\"\n",
    "    n = max(1, n)\n",
    "    return (lst[i:i+n] for i in range(0, len(lst), n))\n",
    "\n",
    "print (f\"workers: {n_workers}, cores/worker:{w_cores}, mem/worker: {w_memory}\")\n",
    "\n",
    "for files_to_process in chunks(s3_files[:n_files], batch_size):\n",
    "\n",
    "    r = work_on_data(client, bucket_name, files_to_process)\n",
    "    print (f\"client:%s Finished %s files\" % (client,len(r)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIA_2\n"
     ]
    }
   ],
   "source": [
    "# take first result, and check for INSTRUME header keyword\n",
    "print (r[0]['INSTRUME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMPLE  =                    T / file does conform to FITS standard             BITPIX  =                   32 / data type of original image                    NAXIS   =                    2 / dimension of original image                    NAXIS1  =                 5000 / length of original image axis                  NAXIS2  =                 5000 / length of original image axis                  REQUESTI= 'NotFromExport'      / Export request id if this program was invoked bDATE    = '2022-12-20T19:06:41.000' / [ISO] Date_time of processing; ISO 8601   TELESCOP= 'SDO/AIA '           / For AIA: SDO/AIA                               INSTRUME= 'AIA_2   '           / For AIA: AIA_ATA1, AIA_ATA2, AIA_ATA3 or AIA_ATWAVELNTH=                  211 / [angstrom] Wavelength                          WAVEUNIT= 'angstrom'           / Wavelength unit: angstrom                      WAVE_STR= '211_THIN'           / Wavelength_FilterPosition                      CAMERA  =                    2 / For AIA: 1, 2, 3  or 4                         ORIGIN  = 'SDO/JSOC-SDP'       / ORIGIN Location where file made                CONTENT = 'Filtergram'         / The type of data product                       FILENAME= 'sdo_aia_h2_20221127T032000_0211_v1.fits' / The filename when created T_OBS   = '2022-11-27T03:19:59.080' / [ISO] Observation time                    T_REC   = '2022.11.27_03:20:23.000_UTC' / [UTC] Observation time                DATE-OBS= '2022-11-27T03:19:57.630' / [ISO] Date when observation started; ISO 8LICENSE = 'CC0-1.0 '           / http://jsoc.stanford.edu/JSOC_Data_Policy.html PROC_LEV= 'level_2HC'          / Proc for HelioCloud, rescaled to 0.5 arc       DATA_DOC= 'DOI:10.1007/s11207-011-9776-8' / Data source document                IMG_TYPE= 'LIGHT   '           / Image type: LIGHT or DARK                      SOURCE  = 'aia.lev1[2022-11-27T03:19:59Z][267091273]' / Input record record     EXPTIME =             2.900766 / [sec] Exposure duration: mean shutter open timeEXPSDEV =       0.000115186798 / [sec] Exposure standard deviation              INT_TIME=              3.15625 / [sec] CCD integration duration                 FSN     =            267091273 / FSN Filtergram Sequence Number                 FID     =                    0 / FID Filtergram ID                              LVL_NUM =                   2. / Data level                                     QUALLEV0=                    0 / Level 0 Quality word                           QUALITY =                    0 / Level 1 Quality word                           CALVER32=            268435456 / Calibration Version                            DEG_COR =            2.4861114 / Filter degradation correction                  HISTORY ver 10 EFF_AREA 0.525614 compensated from 1.306735                      COMMENT No comment                                                              TOTVALS =             16777216 / Expected number of data values (pixels)        DATAVALS=             25000000 / Actual number of data values in image          MISSVALS=             -8222783 / Missing values: TOTVALS                        PERCENTD=                 100. / Percent data; 100*DATAVALS/TOTVALS             DATAMIN =                   -7 / Minimum value of all pixels                    DATAMAX =                11318 / Maximum value of all pixels                    DATAMEDN=                  129 / Median value of all pixels                     DATAMEAN=           245.937607 / Mean value of all pixels                       DATARMS =           400.095276 / Rms deviation from the mean value of all pixelsDATASKEW=           5.13724709 / Skewness from the mean value of all pixels     DATAKURT=           43.9473267 / Kurtosis of all pixels                         OSCNMEAN=                      / (MISSING) Mean value of oversan rows           OSCNRMS =                      / (MISSING) Rms deviation from the mean value of FLAT_REC= 'aia.flatfield[:#694]' / Flatfield series record pointer              CTYPE1  = 'HPLN-TAN'           / CTYPE1: HPLN                                   CUNIT1  = 'arcsec  '           / [arcsec] CUNIT1: arcsec                        CRVAL1  =                   0. / [arcsec] CRVAL1: x origin                      CDELT1  =                  0.5 / [arcsec/pixel] CDELT1: image scale in the x dirCRPIX1  =               2500.5 / [pixel] CRPIX1: location of sun center in CCD xCTYPE2  = 'HPLT-TAN'           / CTYPE2: HPLT                                   CUNIT2  = 'arcsec  '           / [arcsec] CUNIT2: arcsec                        CRVAL2  =                   0. / [arcsec] CRVAL2: y origin                      CDELT2  =                  0.5 / [arcsec/pixel] CDELT2: image scale in the y dirCRPIX2  =               2500.5 / [pixel] CRPIX2: location of sun center in CCD yCROTA2  =                   0. / [degree] CROTA2: INST_ROT + SAT_ROT            R_SUN   =           1944.61914 / [pixel] Radius of the Sun in pixels on the CCD MPO_REC = 'aia.master_pointing3h[:#51848]' / Master Pointing series record pointINST_ROT=         0.0564329997 / [deg] Master pointing CCD rotation wrt SDO Z axIMSCL_MP=          0.600758016 / [arcsec/pixel] Master pointing image scale     X0_MP   =           2035.78894 / [pixel] Master pointing X0 sun center in CCD frY0_MP   =           2038.53345 / [pixel] Master pointing Y0 sun center in CCD frRSUN_LF =                      / [pixel] (MISSING) Limb fit Solar radius        X0_LF   =                      / [pixel] (MISSING) Limb fit X0 sun center in CCDY0_LF   =                      / [pixel] (MISSING) Limb fit Y0 sun center in CCDASD_REC = 'sdo.lev0_asd_0004[:#101149268]' / Ancillary Science Data series recorSAT_Y0  =          -6.24736118 / [arcsec] Position of solar center wrt the SDO  SAT_Z0  =           11.6534405 / [arcsec] Position of solar center wrt the SDO ZSAT_ROT =       9.38218509E-05 / [deg] Angle of solar pole wrt the SDO X axis   ACS_MODE= 'SCIENCE '           / ACS pointing mode                              ACS_ECLP= 'NO      '           / ACS eclipse flag                               ACS_SUNP= 'YES     '           / ACS sun presense flag                          ACS_SAFE= 'NO      '           / ACS safe hold flag                             ACS_CGT = 'GT3     '           / ACS ID of Controlling Guide Telescope          ORB_REC = 'sdo.fds_orbit_vectors[2022.11.27_03:19:00_UTC]' / Orbit vector seriesDSUN_REF=        149597870691. / [m] Reference distance to Sun: 149,597,870,691.DSUN_OBS=   147649309293.83292 / [m] Distance from SDO to Sun center            RSUN_REF=           696000000. / [m] Reference radius of the Sun: 696,000,000.0 RSUN_OBS=   972.30957263365747 / [arcsec] Apparent radius of the Sun seen by SDOGAEX_OBS=   34722132.384332195 / [m] Geocentric Aries Ecliptic X position       GAEY_OBS=  -1157656.9314149029 / [m] Geocentric Aries Ecliptic Y position       GAEZ_OBS=  -23891287.017519519 / [m] Geocentric Aries Ecliptic Z position       HAEX_OBS=   63511318008.048363 / [m] Heliocentric Aries Ecliptic X position     HAEY_OBS=   133291522886.29144 / [m] Heliocentric Aries Ecliptic Y position     HAEZ_OBS=  -30764910.739002224 / [m] Heliocentric Aries Ecliptic Z position     OBS_VR  =   1792.2353756347613 / [m/s] Speed of observer in radial direction    OBS_VW  =   31639.594238015579 / [m/s] Speed of observer in solar               OBS_VN  =  -5197.8821987873589 / [m/s] Speed of observer in solar               CRLN_OBS=           104.268822 / [deg] Carrington longitude of the observer     CRLT_OBS=           1.39732802 / [deg] Carrington latitude of the observer      CAR_ROT =                 2264 / Carrington rotation number of CRLN_OBS         HGLN_OBS=        -0.0134097105 / [deg] Stonyhurst longitude of the observer     ISPSNAME= 'aia.lev0_isp_0011'  / ISP SERIES NAME                                ISPPKTIM= '2022-11-27T03:19:56.007' / [ISO] PACKET_TIME, Prime key value for theISPPKTVN= '001.197 '           / PACKET_VERSION_NUMBER                          AIVNMST =                  453 / AIA_VER_NUM_IMAGE_STATUS                       AIMGOTS =           2048210435 / AIA_IMG_OBT_TIME_SH_SEC                        ASQHDR  =           1340833097 / AIA_SEQ_HEADER                                 ASQTNUM =                    1 / AIA_SEQ_TEL_NUM                                ASQFSN  =            267091273 / AIA_SEQ_FRAME_SN                               AIAHFSN =            267091265 / AIA_IMG_HIST_FSN                               AECDELAY=                 1535 / AIA_IMG_AEC_DELAY                              AIAECTI =                    0 / AIA_IMG_AEC_TABLE_ID                           AIASEN  =                   24 / AIA_IMG_AS_ENCODER                             AIFDBID =                  241 / AIA_IMG_FDB_ID                                 AIMGOTSS=                46227 / AIA_IMG_OBT_TIME_SH_SS                         AIFCPS  =                   62 / AIA_IMG_FC_POSITION                            AIFTSWTH=                    0 / AIA_IMG_FLT_TYPE_SW_TH                         AIFRMLID=                 3337 / AIA_IMG_FRMLIST_ID                             AIFTSID =                40960 / AIA_IMG_FTS_ID                                 AIHISMXB=                    7 / AIA_IMG_HIST_MAX_BIN                           AIHIS192=                    0 / AIA_IMG_HISTC_BN_192                           AIHIS348=              2530978 / AIA_IMG_HISTC_BN_348                           AIHIS604=              7993426 / AIA_IMG_HISTC_BN_604                           AIHIS860=              8388608 / AIA_IMG_HISTC_BN_860                           AIFWEN  =                  204 / AIA_IMG_FW_ENCODER                             AIMGSHCE=                 2900 / AIA_IMG_SH_CMDED_EXPOSURE                      AECTYPE =                    0 / AIA_IMG_AEC_TYPE                               AECMODE = 'ON      '           / AIA_IMG_AEC_MODE                               AISTATE = 'CLOSED  '           / AIA_IMG_ISS_LOOP                               AIAECENF=                    1 / AIA_IMG_AEC_ENA_FLAG                           AIFILTYP=                    0 / AIA_IMG_FILTER_TYPE                            AIMSHOBC=           41.4840012 / AIA_IMG_SH_OPEN_BOT_CENTR                      AIMSHOBE=               26.684 / AIA_IMG_SH_OPEN_BOT_EDGE                       AIMSHOTC=           55.5760002 / AIA_IMG_SH_OPEN_TOP_CENTR                      AIMSHOTE=           69.5159988 / AIA_IMG_SH_OPEN_TOP_EDGE                       AIMSHCBC=            2942.3999 / AIA_IMG_SH_CLOSE_BOT_CENTR                     AIMSHCBE=           2927.28394 / AIA_IMG_SH_CLOSE_BOT_EDGE                      AIMSHCTC=           2956.38794 / AIA_IMG_SH_CLOSE_TOP_CENTR                     AIMSHCTE=           2970.25195 / AIA_IMG_SH_CLOSE_TOP_EDGE                      AICFGDL1=                    0 / AIA_IMG_CFG_DELAY_1                            AICFGDL2=                   24 / AIA_IMG_CFG_DELAY_2                            AICFGDL3=                   88 / AIA_IMG_CFG_DELAY_3                            AICFGDL4=                  236 / AIA_IMG_CFG_DELAY_4                            AIFOENFL=                    1 / AIA_IMG_FOCUS_ENA_FLAG                         AIMGFSN =                    6 / AIA_IMG_FRLIST_POS                             AIMGTYP =                    0 / AIA_IMG_IMAGE_TYPE                             AIAWVLEN=                    2 / AIA_IMG_WAVELENGTH                             AIAGP1  =                    0 / AIA_IMG_GP1                                    AIAGP2  =                    0 / AIA_IMG_GP2                                    AIAGP3  =                    0 / AIA_IMG_GP3                                    AIAGP4  =                    0 / AIA_IMG_GP4                                    AIAGP5  =                    0 / AIA_IMG_GP5                                    AIAGP6  =                    0 / AIA_IMG_GP6                                    AIAGP7  =                    0 / AIA_IMG_GP7                                    AIAGP8  =                  280 / AIA_IMG_GP8                                    AIAGP9  =                  344 / AIA_IMG_GP9                                    AIAGP10 =                  748 / AIA_IMG_GP10                                   AGT1SVY =                   -2 / AIA_GT1_SUNVECTOR_Y                            AGT1SVZ =                  -14 / AIA_GT1_SUNVECTOR_Z                            AGT2SVY =                   -8 / AIA_GT2_SUNVECTOR_Y                            AGT2SVZ =                  -17 / AIA_GT2_SUNVECTOR_Z                            AGT3SVY =                    2 / AIA_GT3_SUNVECTOR_Y                            AGT3SVZ =                    0 / AIA_GT3_SUNVECTOR_Z                            AGT4SVY =                   60 / AIA_GT4_SUNVECTOR_Y                            AGT4SVZ =                  120 / AIA_GT4_SUNVECTOR_Z                            AIMGSHEN=                    4 / AIA_IMG_SH_ENCODER                             TRECSTEP=                  60. / [seconds] JPS: provide a comment {T_REC_step}  TRECEPOC= '1977.01.01_00:00:00.000_TAI' / [TAI] Reference epoch for T_OBS {T_RECRECNUM  =             14655806 / Recnum                                         DRMS_ID = 'aia.lev2_hc:14655806:image_lev2' / DRMS ID                           PRIMARYK= 'T_REC, WAVELNTH, RequestID' / DRMS primary key                       LICENSE = 'LICENSE '           / CC0 1.0                                        BLANK   =          -2147483648                                                  CHECKSUM= 'ePdGgPZGePbGePZG'   / HDU checksum updated 2022-12-20T19:06:35       DATASUM = '4223606560'         / data unit checksum updated 2022-12-20T19:06:35 END                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n"
     ]
    }
   ],
   "source": [
    "print (r[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
