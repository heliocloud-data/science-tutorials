{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to process data in SMCE helio-public S3 bucket using Dask\n",
    "\n",
    "This is a simple example showing how to get a list of FITS files, run them through Dask workers to pull them from disk and examine the header keyword(s). \n",
    "\n",
    "You can use this notebook to test out various parameters you might feed to Dask; Consider the 'batch size', number of workers, number of cores per worker and memory per worker. Use the dashboard link to inspect how Dask is performing. Try both manual and automatic scaling strategies. See if you can get it to process 100 files in 20 sec or less!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First:  What is S3? \n",
    "\n",
    "S3 stands for \"Simple Storage Service,\" which provides object storage for for AWS.  https://aws.amazon.com/s3/ \n",
    "\n",
    "It allows people to query and access data from a common location reference.  The buckets can be made <a href=\"https://stackoverflow.com/q/16784052\">web accessible to users outside of daskhub</a> if web access is enabled.    \n",
    "\n",
    "S3 buckets are individual storage elements. \n",
    "\n",
    "## Accessing S3 buckets\n",
    "\n",
    "To <a href= \"https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/ls.html\">get a list of the S3 buckets</a> on the SMCE Daskhub, enter this at a terminal prompt : <br>\n",
    "`aws s3 ls`\n",
    "\n",
    "To view the contents of a specific bucket, reference it with s3:// <br>\n",
    "`aws s3 ls s3://helio-public/`\n",
    ">            PRE SDO/\n",
    ">            PRE SOHO/\n",
    "\n",
    "(Note: \"PRE\" stands for prefix, so SDO/ is an AWS prefix with name SDO.) \n",
    "<hr>\n",
    "\n",
    "The external reference for this bucket is https://helio-public.s3.us-east-1.amazonaws.com/\n",
    "\n",
    "## Basic commands using S3 buckets\n",
    "\n",
    "To create a new directory, just reference it:<br>\n",
    "`aws s3 ls s3://helio-public/yourname/yourdir`\n",
    "\n",
    "then you can copy to the bucket as if it was a unix folder:<br>\n",
    "`aws s3 cp yourfile s3://helio-public/yourname/yourdir`\n",
    "\n",
    "if you need access to a bucket that has restricted access, you have to run aws-mfa first:<br>\n",
    "`~/aws-mfa default`\n",
    "\n",
    "you may need to change it to have execute permission first:<br>\n",
    "`chmod 755 ~/aws-mfa`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import dask\n",
    "import io\n",
    "import logging\n",
    "import s3fs\n",
    "\n",
    "from astropy.io import fits\n",
    "from dask.distributed import Client\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the bucket to upload to\n",
    "bucket_name = 'helio-public'\n",
    "\n",
    "# location in the bucket to use\n",
    "bucket_path = '/SDO/AIA/'\n",
    "\n",
    "# number of workers to use, for automatic scaling, our max number\n",
    "n_workers = 4\n",
    "\n",
    "# memory per worker (in Gb)\n",
    "w_memory = 2\n",
    "\n",
    "# cores per worker\n",
    "w_cores = 2\n",
    "\n",
    "# number of files to test against\n",
    "n_files = 100\n",
    "\n",
    "# Number of files we release to be worked on by all workers at a time\n",
    "# the higher the number the more files being processed concurrently, but also\n",
    "# the greater the memory consumed. \n",
    "batch_size = 50\n",
    "\n",
    "# use Manual (if False, then uses Automatic scaling)\n",
    "use_manual_scaling = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize the cluster and assign the client to the cluster, display the cluster widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway, GatewayCluster\n",
    "gateway = Gateway()\n",
    "options = gateway.cluster_options()\n",
    "\n",
    "# We're setting some defaults here just for grins... \n",
    "# I like the pangeo/base-notebook image for the workers since it has almost every library you'd need on a worker\n",
    "# In our environment, without setting these, the widget will default to the same image that the notebook itself is running, \n",
    "# as well as 2 cores and 4GB memory per worker\n",
    "\n",
    "options.worker_cores=w_cores\n",
    "options.worker_memory=w_memory\n",
    "# options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = gateway.new_cluster(options)\n",
    "client = cluster.get_client()\n",
    "\n",
    "if use_manual_scaling:\n",
    "    \n",
    "    # manual scaling (n_workers defined above)\n",
    "    cluster.scale(n_workers)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Adaptively scale between 1 and n_workers (the max)\n",
    "    cluster.adapt(minimum=1, maximum=n_workers)\n",
    "\n",
    "# uncomment this if you want to use the GUI\n",
    "#cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>gateway://traefik-daskhub-dask-gateway.daskhub:80/daskhub.8f7fddba87cb4e7daae1e2cfc2e2c531</li>\n",
       "  <li><b>Dashboard: </b><a href='/services/dask-gateway/clusters/daskhub.8f7fddba87cb4e7daae1e2cfc2e2c531/status' target='_blank'>/services/dask-gateway/clusters/daskhub.8f7fddba87cb4e7daae1e2cfc2e2c531/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>0</li>\n",
       "  <li><b>Cores: </b>0</li>\n",
       "  <li><b>Memory: </b>0 B</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tls://192.168.20.127:8786' processes=0 threads=0, memory=0 B>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create client, show url we can go to to monitor progress\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scan data from bucket and make a simple list of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize connection to S3 bucket\n",
    "s3_client = boto3.resource('s3')\n",
    "bucket = s3_client.Bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SDO/AIA/AIA_L4_20141018_000001_94.fits'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get our list of files/s3 objects\n",
    "\n",
    "# Iterates through all the objects, doing the pagination for you. Each obj\n",
    "# is an ObjectSummary, so it doesn't contain the body. You'll need to call\n",
    "# get to get the whole body.\n",
    "s3_files = []\n",
    "for obj in bucket.objects.all():\n",
    "    key = obj.key\n",
    "\n",
    "    if search ('fits', key):\n",
    "        s3_files.append(obj.key)\n",
    "\n",
    "s3_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define some routines we will use for doing work with Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_fits_s3 (s3_file_name:str, bucket_name:str)->object:\n",
    "    \n",
    "    \"\"\" Open a FITS file on an S3 bucket, pass back a binary blob of file info.\n",
    "    \"\"\"\n",
    "     \n",
    "    fs = s3fs.S3FileSystem()\n",
    "    \n",
    "    with fs.open(bucket_name+'/'+s3_file_name, 'rb') as f:\n",
    "        #fits_hdul = fits.open(io.BytesIO(f.read()))\n",
    "        # fits_hdul.info()\n",
    "    \n",
    "        # return bytes\n",
    "        return f.read()\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_header(f_bytes:object)->str:\n",
    "    \n",
    "    \"\"\" Marshal the binary blob into a astropy FITS object, then read the header and pass back \n",
    "    \"\"\"\n",
    "    try: \n",
    "        hdul = fits.open(io.BytesIO(f_bytes))\n",
    "        return hdul[0].header\n",
    "    except Exception as ex:\n",
    "        # bad file? Some of these are missing the END keyword!!\n",
    "        # for now, lets simply side-step it and move on\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "    \n",
    "def work_on_data (client:dask.distributed.client.Client, bucket_name:str, files:list=[])->int:\n",
    "    \n",
    "    \"\"\" \n",
    "    Main routine which Dask will use to 'do work'. Each worker will run this.\n",
    "    \"\"\"\n",
    "    \n",
    "    # pull files from S3 as bytes\n",
    "    f_bytes_list = client.map(open_fits_s3, files, bucket_name=bucket_name)\n",
    "    \n",
    "    # read bytes as FITS file, grab header\n",
    "    hduls = client.map(get_header, f_bytes_list)\n",
    "    \n",
    "    # trigger distributed task, marshall result back to local memory\n",
    "    headers = client.gather(hduls)\n",
    "    \n",
    "    # return a result of some kind, lets parse gathered headers to return value of the \n",
    "    # AIL1FILE keyword\n",
    "    return [hdr['AIL1FILE'] for hdr in headers if hdr != None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Do the cloud processing, using Dask to 'burst' into other VMs\n",
    "Using our gathered list of FITS files, chunk it out in batches and provide file list chunks to the workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workers: 4, cores/worker:2, mem/worker: 2\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def chunks(lst, n):\n",
    "    \"\"\" program to divide our file list into chunks for each worker \"\"\"\n",
    "    n = max(1, n)\n",
    "    return (lst[i:i+n] for i in range(0, len(lst), n))\n",
    "\n",
    "print (f\"workers: {n_workers}, cores/worker:{w_cores}, mem/worker: {w_memory}\")\n",
    "\n",
    "for files_to_process in chunks(s3_files[:n_files], batch_size):\n",
    "\n",
    "    r = work_on_data(client, bucket_name, files_to_process)\n",
    "    print (f\"client:%s Finished %s files\" % (client,len(r)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:s3-demo]",
   "language": "python",
   "name": "conda-env-s3-demo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
